{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models.segmentation import deeplabv3_resnet50\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "device = 'cuda'\n",
    "NUM_CLASSES = 3  # пример: фон, класс_1, класс_2\n",
    "model = deeplabv3_resnet50(pretrained=True, num_classes=NUM_CLASSES)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # target: [B, H, W] c метками 0..N–1\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "img_tfm = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "mask_tfm = transforms.Compose([\n",
    "    transforms.Resize((256, 256), interpolation=Image.NEAREST),\n",
    "    transforms.PILToTensor()  # оставит маску как uint8 [1, H, W]\n",
    "])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "data/\n",
    "├── train/\n",
    "│   ├── images/\n",
    "│   │   ├── img_001.jpg\n",
    "│   │   └── ...\n",
    "│   └── masks/\n",
    "│       ├── img_001.png     # 1-канальная маска: значения 0, 1, 2...\n",
    "│       └── ...\n",
    "├── test/\n",
    "│   └── images/\n",
    "│       ├── test_001.jpg\n",
    "│       └── ...\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "class SegDataset(Dataset):\n",
    "    def __init__(self, img_dir, mask_dir, tfm_img, tfm_mask):\n",
    "        self.img_paths = sorted(Path(img_dir).glob('*.jpg'))\n",
    "        self.mask_dir = Path(mask_dir)\n",
    "        self.tfm_img = tfm_img\n",
    "        self.tfm_mask = tfm_mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_paths[idx]\n",
    "        mask_path = self.mask_dir / (img_path.stem + '.png')\n",
    "\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        mask = Image.open(mask_path).convert('L')  # grayscale\n",
    "\n",
    "        img = self.tfm_img(img)\n",
    "        mask = self.tfm_mask(mask).squeeze(0).long()  # [H, W]\n",
    "\n",
    "        return img, mask\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_dir, tfm_img):\n",
    "        self.img_paths = sorted(Path(img_dir).glob('*.jpg'))\n",
    "        self.tfm_img = tfm_img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_paths[idx]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        return self.tfm_img(img), img_path.name\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_ds = SegDataset('data/train/images', 'data/train/masks', img_tfm, mask_tfm)\n",
    "train_dl = DataLoader(train_ds, batch_size=8, shuffle=True)\n",
    "\n",
    "test_ds = TestDataset('data/test/images', img_tfm)\n",
    "test_dl = DataLoader(test_ds, batch_size=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "model.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    for imgs, masks in train_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        masks = masks.to(device)  # [B, H, W]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(imgs)['out']     # [B, C, H, W]\n",
    "        loss = criterion(output, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Loss = {total_loss:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    pred_logits = model(img.unsqueeze(0).to(device))['out']  # [1, C, H, W]\n",
    "    pred_mask = pred_logits.argmax(1).squeeze(0).cpu()       # [H, W], значения 0..C–1\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# pred_mask: тензор маски, размер [B, C, H, W] или [C, H, W]\n",
    "# orig_size: оригинальный размер, к которому надо вернуть — (H, W)\n",
    "\n",
    "# Пример: если был ресайз до 256x256, а оригинал был 101x101\n",
    "orig_size = (101, 101)\n",
    "restored_mask = F.interpolate(pred_mask.unsqueeze(0).float(), size=orig_size, mode='bilinear', align_corners=False).squeeze(0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "binary_mask = (restored_mask > 0.5).float()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}