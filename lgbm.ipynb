{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "            id      Podcast_Name Episode_Title  Episode_Length_minutes  \\\n0            0   Mystery Matters    Episode 98                     NaN   \n1            1     Joke Junction    Episode 26                  119.80   \n2            2    Study Sessions    Episode 16                   73.90   \n3            3    Digital Digest    Episode 45                   67.17   \n4            4       Mind & Body    Episode 86                  110.51   \n...        ...               ...           ...                     ...   \n749995  749995      Learning Lab    Episode 25                   75.66   \n749996  749996   Business Briefs    Episode 21                   75.75   \n749997  749997  Lifestyle Lounge    Episode 51                   30.98   \n749998  749998       Style Guide    Episode 47                  108.98   \n749999  749999    Sports Central    Episode 99                   24.10   \n\n             Genre  Host_Popularity_percentage Publication_Day  \\\n0       True Crime                       74.81        Thursday   \n1           Comedy                       66.95        Saturday   \n2        Education                       69.97         Tuesday   \n3       Technology                       57.22          Monday   \n4           Health                       80.07          Monday   \n...            ...                         ...             ...   \n749995   Education                       69.36        Saturday   \n749996    Business                       35.21        Saturday   \n749997   Lifestyle                       78.58        Thursday   \n749998   Lifestyle                       45.39        Thursday   \n749999      Sports                       22.45        Saturday   \n\n       Publication_Time  Guest_Popularity_percentage  Number_of_Ads  \\\n0                 Night                          NaN            0.0   \n1             Afternoon                        75.95            2.0   \n2               Evening                         8.97            0.0   \n3               Morning                        78.70            2.0   \n4             Afternoon                        58.68            3.0   \n...                 ...                          ...            ...   \n749995          Morning                          NaN            0.0   \n749996            Night                          NaN            2.0   \n749997          Morning                        84.89            0.0   \n749998          Morning                        93.27            0.0   \n749999            Night                        36.72            0.0   \n\n       Episode_Sentiment  Listening_Time_minutes  \n0               Positive                31.41998  \n1               Negative                88.01241  \n2               Negative                44.92531  \n3               Positive                46.27824  \n4                Neutral                75.61031  \n...                  ...                     ...  \n749995          Negative                56.87058  \n749996           Neutral                45.46242  \n749997          Negative                15.26000  \n749998          Negative               100.72939  \n749999           Neutral                11.94439  \n\n[750000 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Podcast_Name</th>\n      <th>Episode_Title</th>\n      <th>Episode_Length_minutes</th>\n      <th>Genre</th>\n      <th>Host_Popularity_percentage</th>\n      <th>Publication_Day</th>\n      <th>Publication_Time</th>\n      <th>Guest_Popularity_percentage</th>\n      <th>Number_of_Ads</th>\n      <th>Episode_Sentiment</th>\n      <th>Listening_Time_minutes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Mystery Matters</td>\n      <td>Episode 98</td>\n      <td>NaN</td>\n      <td>True Crime</td>\n      <td>74.81</td>\n      <td>Thursday</td>\n      <td>Night</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>Positive</td>\n      <td>31.41998</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Joke Junction</td>\n      <td>Episode 26</td>\n      <td>119.80</td>\n      <td>Comedy</td>\n      <td>66.95</td>\n      <td>Saturday</td>\n      <td>Afternoon</td>\n      <td>75.95</td>\n      <td>2.0</td>\n      <td>Negative</td>\n      <td>88.01241</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Study Sessions</td>\n      <td>Episode 16</td>\n      <td>73.90</td>\n      <td>Education</td>\n      <td>69.97</td>\n      <td>Tuesday</td>\n      <td>Evening</td>\n      <td>8.97</td>\n      <td>0.0</td>\n      <td>Negative</td>\n      <td>44.92531</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Digital Digest</td>\n      <td>Episode 45</td>\n      <td>67.17</td>\n      <td>Technology</td>\n      <td>57.22</td>\n      <td>Monday</td>\n      <td>Morning</td>\n      <td>78.70</td>\n      <td>2.0</td>\n      <td>Positive</td>\n      <td>46.27824</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Mind &amp; Body</td>\n      <td>Episode 86</td>\n      <td>110.51</td>\n      <td>Health</td>\n      <td>80.07</td>\n      <td>Monday</td>\n      <td>Afternoon</td>\n      <td>58.68</td>\n      <td>3.0</td>\n      <td>Neutral</td>\n      <td>75.61031</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>749995</th>\n      <td>749995</td>\n      <td>Learning Lab</td>\n      <td>Episode 25</td>\n      <td>75.66</td>\n      <td>Education</td>\n      <td>69.36</td>\n      <td>Saturday</td>\n      <td>Morning</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>Negative</td>\n      <td>56.87058</td>\n    </tr>\n    <tr>\n      <th>749996</th>\n      <td>749996</td>\n      <td>Business Briefs</td>\n      <td>Episode 21</td>\n      <td>75.75</td>\n      <td>Business</td>\n      <td>35.21</td>\n      <td>Saturday</td>\n      <td>Night</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>Neutral</td>\n      <td>45.46242</td>\n    </tr>\n    <tr>\n      <th>749997</th>\n      <td>749997</td>\n      <td>Lifestyle Lounge</td>\n      <td>Episode 51</td>\n      <td>30.98</td>\n      <td>Lifestyle</td>\n      <td>78.58</td>\n      <td>Thursday</td>\n      <td>Morning</td>\n      <td>84.89</td>\n      <td>0.0</td>\n      <td>Negative</td>\n      <td>15.26000</td>\n    </tr>\n    <tr>\n      <th>749998</th>\n      <td>749998</td>\n      <td>Style Guide</td>\n      <td>Episode 47</td>\n      <td>108.98</td>\n      <td>Lifestyle</td>\n      <td>45.39</td>\n      <td>Thursday</td>\n      <td>Morning</td>\n      <td>93.27</td>\n      <td>0.0</td>\n      <td>Negative</td>\n      <td>100.72939</td>\n    </tr>\n    <tr>\n      <th>749999</th>\n      <td>749999</td>\n      <td>Sports Central</td>\n      <td>Episode 99</td>\n      <td>24.10</td>\n      <td>Sports</td>\n      <td>22.45</td>\n      <td>Saturday</td>\n      <td>Night</td>\n      <td>36.72</td>\n      <td>0.0</td>\n      <td>Neutral</td>\n      <td>11.94439</td>\n    </tr>\n  </tbody>\n</table>\n<p>750000 rows Ã— 12 columns</p>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm\n",
    "import optuna\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "Publication_Time\nNight        196849\nEvening      195778\nAfternoon    179460\nMorning      177913\nName: count, dtype: int64"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Publication_Time'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def derive_episode(episode):\n",
    "    return int(episode.split()[-1])\n",
    "def num(r):\n",
    "    return len(str(r))\n",
    "def process(df):\n",
    "    df['Genre'] = df['Genre'].astype('category')\n",
    "    df['Publication_Day'] = df['Publication_Day'].astype('category')\n",
    "    df['Publication_Time'] = df['Publication_Time'].astype('category')\n",
    "    df['Episode_Sentiment'] = df['Episode_Sentiment'].astype('category')\n",
    "    df['Podcast_Name'] = df['Podcast_Name'].astype('category')\n",
    "    df['Host_Popularity_percentage'] = df['Host_Popularity_percentage']\n",
    "    df['Guest_Popularity_percentage'] = df['Guest_Popularity_percentage']\n",
    "    df['num_decimals'] = df['Episode_Length_minutes'].apply(num)\n",
    "    df['Episode_Num'] = df['Episode_Title'].apply(derive_episode)\n",
    "    return df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df = process(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# X = df.drop(columns=['Episode_Title', 'Listening_Time_minutes'])\n",
    "# y = df['Listening_Time_minutes']\n",
    "#\n",
    "# dtrain = lightgbm.Dataset(X,label=y,categorical_feature=['Podcast_Name','Genre','Publication_Day','Publication_Time','Episode_Sentiment'])\n",
    "#\n",
    "# params = {\n",
    "#     \"objective\": \"regression\",\n",
    "#     \"metric\": \"rmse\",\n",
    "#     \"learning_rate\": 0.01,         # stable learning\n",
    "#     \"feature_fraction\": 0.9,       # avoid overfitting by feature bagging\n",
    "#     \"bagging_fraction\": 0.9,       # row bagging per tree\n",
    "#     \"bagging_freq\": 1,             # actually apply the bagging\n",
    "#     \"random_state\": 42,\n",
    "#     \"verbosity\": -1\n",
    "# }\n",
    "\n",
    "#\n",
    "# model = lightgbm.train(params,train_set=dtrain,num_boost_round=5000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-02 03:55:24,302] A new study created in memory with name: no-name-8b04c558-b391-4dd7-86f3-986be7d5cd9b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds\n",
      "Early stopping, best iteration is:\n",
      "[311]\tvalid's rmse: 12.9158\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "Early stopping, best iteration is:\n",
      "[551]\tvalid's rmse: 12.976\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "Early stopping, best iteration is:\n",
      "[488]\tvalid's rmse: 12.9639\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "Early stopping, best iteration is:\n",
      "[339]\tvalid's rmse: 12.9576\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "Early stopping, best iteration is:\n",
      "[462]\tvalid's rmse: 12.9119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-02 03:56:55,588] Trial 0 finished with value: 167.57433816572754 and parameters: {'learning_rate': 0.07535984342570455, 'num_leaves': 234, 'min_data_in_leaf': 41, 'feature_fraction': 0.6601604784747851, 'bagging_fraction': 0.7006497414601343, 'bagging_freq': 3, 'lambda_l1': 4.847016200788929, 'lambda_l2': 3.756228299270301}. Best is trial 0 with value: 167.57433816572754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds\n",
      "Early stopping, best iteration is:\n",
      "[150]\tvalid's rmse: 12.9653\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "Early stopping, best iteration is:\n",
      "[169]\tvalid's rmse: 13.0255\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "Early stopping, best iteration is:\n",
      "[249]\tvalid's rmse: 13.001\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "Early stopping, best iteration is:\n",
      "[220]\tvalid's rmse: 12.9944\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "Early stopping, best iteration is:\n",
      "[116]\tvalid's rmse: 12.9629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-02 03:58:01,089] Trial 1 finished with value: 168.7361975543747 and parameters: {'learning_rate': 0.09748328828644448, 'num_leaves': 252, 'min_data_in_leaf': 22, 'feature_fraction': 0.7713339090765571, 'bagging_fraction': 0.6610111490885451, 'bagging_freq': 3, 'lambda_l1': 1.4643588327562396, 'lambda_l2': 2.9218982264483695}. Best is trial 0 with value: 167.57433816572754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds\n",
      "Early stopping, best iteration is:\n",
      "[437]\tvalid's rmse: 12.9131\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "Early stopping, best iteration is:\n",
      "[521]\tvalid's rmse: 12.9701\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "Early stopping, best iteration is:\n",
      "[609]\tvalid's rmse: 12.9547\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "Early stopping, best iteration is:\n",
      "[487]\tvalid's rmse: 12.9628\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "Early stopping, best iteration is:\n",
      "[520]\tvalid's rmse: 12.9299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-02 03:59:29,491] Trial 2 finished with value: 167.6029174478721 and parameters: {'learning_rate': 0.08107249493087879, 'num_leaves': 175, 'min_data_in_leaf': 82, 'feature_fraction': 0.6237277769303173, 'bagging_fraction': 0.7391178144357118, 'bagging_freq': 5, 'lambda_l1': 0.6054441355028584, 'lambda_l2': 0.9142388491491527}. Best is trial 0 with value: 167.57433816572754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds\n",
      "Early stopping, best iteration is:\n",
      "[297]\tvalid's rmse: 12.9493\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "Early stopping, best iteration is:\n",
      "[481]\tvalid's rmse: 12.9984\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "Early stopping, best iteration is:\n",
      "[517]\tvalid's rmse: 12.9847\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "Early stopping, best iteration is:\n",
      "[451]\tvalid's rmse: 12.9766\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "Early stopping, best iteration is:\n",
      "[347]\tvalid's rmse: 12.9372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-02 04:00:56,989] Trial 3 finished with value: 168.2017968481121 and parameters: {'learning_rate': 0.08007129587546154, 'num_leaves': 206, 'min_data_in_leaf': 76, 'feature_fraction': 0.6545963584250651, 'bagging_fraction': 0.66267539478362, 'bagging_freq': 6, 'lambda_l1': 1.4157573370230052, 'lambda_l2': 1.8193567513326603}. Best is trial 0 with value: 167.57433816572754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9891]\tvalid's rmse: 12.8553\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9774]\tvalid's rmse: 12.8997\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid's rmse: 12.8815\n",
      "Training until validation scores don't improve for 500 rounds\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=['Episode_Title', 'Listening_Time_minutes'])\n",
    "y = df['Listening_Time_minutes']\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "def objective(trial):\n",
    "\n",
    "    param = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'random_state': 42,\n",
    "        'learning_rate': trial.suggest_float(\"learning_rate\", 0.005, 0.1),\n",
    "        'num_leaves': trial.suggest_int(\"num_leaves\", 16, 256),\n",
    "        'min_data_in_leaf': trial.suggest_int(\"min_data_in_leaf\", 10, 100),\n",
    "        'feature_fraction': trial.suggest_float(\"feature_fraction\", 0.6, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float(\"bagging_fraction\", 0.6, 1.0),\n",
    "        'bagging_freq': trial.suggest_int(\"bagging_freq\", 1, 10),\n",
    "        'lambda_l1': trial.suggest_float(\"lambda_l1\", 0.0, 5.0),\n",
    "        'lambda_l2': trial.suggest_float(\"lambda_l2\", 0.0, 5.0)\n",
    "    }\n",
    "\n",
    "    kf = KFold(n_splits=5, random_state=42,shuffle=True)\n",
    "    loss_list = []\n",
    "    best_iters = []\n",
    "\n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        dtrain = lightgbm.Dataset(X.iloc[train_idx],label=y.iloc[train_idx])\n",
    "        dvalid = lightgbm.Dataset(X.iloc[val_idx],label=y.iloc[val_idx])\n",
    "\n",
    "        model = lightgbm.train(\n",
    "            param,\n",
    "            dtrain,\n",
    "            num_boost_round=10000,\n",
    "            valid_sets=[dvalid],\n",
    "            valid_names=['valid'],\n",
    "            callbacks=[\n",
    "                lightgbm.early_stopping(stopping_rounds=500)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        preds = model.predict(X.iloc[val_idx])\n",
    "        loss = mean_squared_error(y.iloc[val_idx], preds)\n",
    "        loss_list.append(loss)\n",
    "        best_iters.append(model.best_iteration)\n",
    "\n",
    "    trial.set_user_attr(\"best_iteration\", int(np.mean(best_iters)))\n",
    "    return np.mean(loss_list)\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective,n_trials=30, timeout=60*10)\n",
    "full_train = lightgbm.Dataset(X,label=y)\n",
    "model = lightgbm.train(study.best_trial.params,train_set=full_train,num_boost_round=study.best_trial.user_attrs['best_iteration'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv')\n",
    "test_df = process(test_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_df['Listening_Time_minutes'] = model.predict(test_df.drop(columns=['Episode_Title']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "submission = test_df[['id','Listening_Time_minutes']]\n",
    "submission"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv',index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}