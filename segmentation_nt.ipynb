{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from PIL import Image\n",
    "\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Use GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "              id                                           rle_mask\n0     2c45b152f1  99 3 197 6 295 9 395 10 494 12 594 13 694 14 7...\n1     3cb59a4fdc                                             1 5656\n2     e185ab5dc1  4647 2 4748 10 4849 18 4950 25 5051 29 5152 34...\n3     c78c89577c                                              101 1\n4     6306dd3a8e  1 30 102 29 203 29 304 28 405 27 506 27 607 26...\n...          ...                                                ...\n3995  429b289e07  1 6463 6465 98 6566 97 6667 95 6768 94 6869 93...\n3996  5d752d6d4a                                                NaN\n3997  26527458de                                                NaN\n3998  25fb3a895a                                                NaN\n3999  f30c36bf6b                                                NaN\n\n[4000 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>rle_mask</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2c45b152f1</td>\n      <td>99 3 197 6 295 9 395 10 494 12 594 13 694 14 7...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3cb59a4fdc</td>\n      <td>1 5656</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>e185ab5dc1</td>\n      <td>4647 2 4748 10 4849 18 4950 25 5051 29 5152 34...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>c78c89577c</td>\n      <td>101 1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6306dd3a8e</td>\n      <td>1 30 102 29 203 29 304 28 405 27 506 27 607 26...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3995</th>\n      <td>429b289e07</td>\n      <td>1 6463 6465 98 6566 97 6667 95 6768 94 6869 93...</td>\n    </tr>\n    <tr>\n      <th>3996</th>\n      <td>5d752d6d4a</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3997</th>\n      <td>26527458de</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3998</th>\n      <td>25fb3a895a</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3999</th>\n      <td>f30c36bf6b</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>4000 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_images_dir = 'train/images'\n",
    "train_masks_dir = 'train/masks'\n",
    "\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((101, 101)),\n",
    "    transforms.ToTensor()\n",
    "])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class SaltDataset(Dataset):\n",
    "    def __init__(self,df,img_dir,mask_dir,transform=None):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, (self.df.iloc[idx]['id']+'.png'))\n",
    "        mask_path = os.path.join(self.mask_dir, (self.df.iloc[idx]['id']+'.png'))\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        mask = Image.open(mask_path).convert('L')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = self.transform(mask)\n",
    "        mask = (mask>0.5).float()\n",
    "        return image, mask"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# ----------------------- 5. CV – U‑Net (binary) --------------------\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_c=3, out_c=1, feats=[64,128,256]):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        prev = in_c\n",
    "        for f in feats:\n",
    "            self.encoder.append(self.double_conv(prev, f))\n",
    "            prev = f\n",
    "        self.bottleneck = self.double_conv(feats[-1], feats[-1]*2)\n",
    "\n",
    "        self.up_trans = nn.ModuleList()\n",
    "        self.decoder  = nn.ModuleList()\n",
    "        for f in feats[::-1]:\n",
    "            self.up_trans.append(nn.ConvTranspose2d(f*2, f, 2, stride=2))\n",
    "            self.decoder.append(self.double_conv(f*2, f))\n",
    "\n",
    "        self.final = nn.Conv2d(feats[0], out_c, 1)\n",
    "\n",
    "    @staticmethod\n",
    "    def double_conv(in_c, out_c):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, 3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_c, out_c, 3, padding=1), nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        skips = []\n",
    "        for down in self.encoder:\n",
    "            x = down(x)\n",
    "            skips.append(x)\n",
    "            x = self.pool(x)\n",
    "\n",
    "        x = self.bottleneck(x)\n",
    "        skips = skips[::-1]\n",
    "\n",
    "        for idx in range(len(self.up_trans)):\n",
    "            x = self.up_trans[idx](x)\n",
    "            skip = skips[idx]\n",
    "            if x.shape != skip.shape:  # если размеры не совпали\n",
    "                x = nn.functional.interpolate(x, size=skip.shape[2:])\n",
    "            x = torch.cat([skip, x], dim=1)\n",
    "            x = self.decoder[idx](x)\n",
    "\n",
    "        return self.final(x)          # логиты маски\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "train_set = SaltDataset(df,train_images_dir,train_masks_dir,transform)\n",
    "train_dataloader = DataLoader(train_set, batch_size=8, shuffle=True)\n",
    "model = UNet().to(device)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.01)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "image, mask = train_set[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 101, 101])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Train Loss: 63.6802\n",
      "Epoch 2 - Train Loss: 0.5608\n",
      "Epoch 3 - Train Loss: 0.5611\n",
      "Epoch 4 - Train Loss: 0.5606\n",
      "Epoch 5 - Train Loss: 0.5613\n",
      "Epoch 6 - Train Loss: 0.5603\n",
      "Epoch 7 - Train Loss: 0.5613\n",
      "Epoch 8 - Train Loss: 0.5609\n",
      "Epoch 9 - Train Loss: 0.5610\n",
      "Epoch 10 - Train Loss: 0.5608\n",
      "Epoch 11 - Train Loss: 0.5610\n",
      "Epoch 12 - Train Loss: 0.5605\n",
      "Epoch 13 - Train Loss: 0.5608\n",
      "Epoch 14 - Train Loss: 0.5607\n",
      "Epoch 15 - Train Loss: 0.5609\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 15  # Reduce for Kaggle runtime limits\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_loss /= len(train_dataloader)\n",
    "    print(f\"Epoch {epoch+1} - Train Loss: {train_loss:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "test = pd.read_csv('sample_submission.csv')\n",
    "model.eval()\n",
    "def rle_encode(mask):\n",
    "    pixels = mask.flatten(order='F')  # по колонкам (Fortran order)\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "submission = []\n",
    "with torch.inference_mode():\n",
    "    for img_id in test['id']:\n",
    "        img_path = os.path.join('test/images',img_id+'.png')\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "        y_pred = model(img_tensor)\n",
    "        mask = (torch.sigmoid(y_pred)>0.5).float()\n",
    "        mask_np = mask.squeeze().cpu().numpy().astype(np.uint8)\n",
    "\n",
    "        rle = rle_encode(mask_np)\n",
    "        submission.append((img_id,rle))\n",
    "\n",
    "df_submission = pd.DataFrame(submission,columns=['id','rle_mask'])\n",
    "df_submission.to_csv('submission.csv',index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}